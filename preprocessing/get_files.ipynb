{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T13:24:14.284020500Z",
     "start_time": "2024-11-01T13:24:14.256655200Z"
    }
   },
   "id": "126f47cef47f88d0"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "aphasia_type = ['wernicke', 'conduction', 'anomic', 'not aphasic']\n",
    "eng_results_fp = \"../ab_data/english-results-data (8).xlsx\"\n",
    "time1_df = pd.read_excel(eng_results_fp, sheet_name='Time 1')\n",
    "repeats_df = pd.read_excel(eng_results_fp, sheet_name='Repeats')\n",
    "\n",
    "time1_df = time1_df[['Participant ID', 'WAB Type']]\n",
    "repeats_df = repeats_df[['Participant ID', 'WAB Type']]\n",
    "\n",
    "files_df = pd.concat([time1_df,repeats_df])\n",
    "files_df = files_df.drop_duplicates()\n",
    "files_df['WAB Type'] = [str(x).lower() for x in files_df['WAB Type']]\n",
    "files_df = files_df[files_df['WAB Type'].isin(aphasia_type)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T13:24:15.901871900Z",
     "start_time": "2024-11-01T13:24:14.272012600Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "filenames = []\n",
    "\n",
    "for index, row in files_df.iterrows():\n",
    "    filenames.append(str(row['Participant ID']+'.cha'))\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T13:24:15.924600100Z",
     "start_time": "2024-11-01T13:24:15.906871400Z"
    }
   },
   "id": "af7006c009239298"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093-1.cha\n",
      "1056-1.cha\n",
      "1022-1.cha\n",
      "1026-LARC.cha\n",
      "1029-LARC.cha\n",
      "1049-LARC.cha\n",
      "1060-LARC.cha\n",
      "1065-4.cha\n",
      "1065-5.cha\n",
      "1065-6.cha\n",
      "1065-LARC.cha\n",
      "1069-LARC.cha\n",
      "1077-LARC.cha\n",
      "1079-LARC.cha\n",
      "1084-LARC.cha\n",
      "1089-LARC.cha\n",
      "1093-LARC.cha\n",
      "1104-LARC.cha\n",
      "1109-LARC.cha\n",
      "1110-LARC.cha\n",
      "1113-LARC.cha\n",
      "1114-LARC.cha\n",
      "55-2.cha\n",
      "TCU10b.cha\n"
     ]
    }
   ],
   "source": [
    "filepaths = []\n",
    "\n",
    "for f in filenames:\n",
    "    path = Path(\"..\\\\ab_data\\\\all_cha\")\n",
    "    if 'NEURAL-2-' in f:\n",
    "        path = str(path) + \"\\\\NEURAL-2\\\\\"\n",
    "        f = re.findall(r'(?<=NEURAL-2-).*',f)[0]\n",
    "    elif 'NEURAL' in f:\n",
    "        path = str(path) + \"\\\\NEURAL\\\\\"\n",
    "        f = re.findall(r'(?<=NEURAL).*',f)[0]\n",
    "    elif 'UMD-' in f:\n",
    "        path = str(path) + \"\\\\UMD\\\\\"\n",
    "        f = re.findall(r'(?<=UMD-).*',f)[0]\n",
    "    elif 'fridriksson-2-' in f:\n",
    "        path = str(path) + \"\\\\Fridriksson-2\\\\\"\n",
    "        f = re.findall(r'(?<=fridriksson-2-).*',f)[0]\n",
    "    exists = False\n",
    "    \n",
    "    if 'NEURAL' in str(path) or 'UMD' in str(path) or 'fridriksson-2-' in str(path):\n",
    "        if os.path.exists(str(path)+f):\n",
    "            exists = True \n",
    "            filepaths.append(str(path)+f)\n",
    "    \n",
    "    else:\n",
    "        for dir, sub_dirs, files in os.walk(path):\n",
    "            if os.path.exists(dir+'\\\\'+f):\n",
    "                exists = True\n",
    "                filepaths.append(dir+'\\\\'+f)\n",
    "                break\n",
    "    if not exists:\n",
    "        filepaths.append(None)\n",
    "        print(f)\n",
    "\n",
    "files_df['path'] = filepaths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T13:24:16.763373700Z",
     "start_time": "2024-11-01T13:24:15.924600100Z"
    }
   },
   "id": "1913322396236d72"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAB: wernicke\n",
      "Found datafiles in excel: 64\n",
      "Missing datafiles: 1\n",
      "Missing files:\n",
      "['fridriksson-2-1089-LARC']\n",
      "\n",
      "WAB: conduction\n",
      "Found datafiles in excel: 157\n",
      "Missing datafiles: 7\n",
      "Missing files:\n",
      "['fridriksson-2-1056-1', 'fridriksson-2-1060-LARC', 'fridriksson-2-1077-LARC', 'fridriksson-2-1079-LARC', 'fridriksson-2-1110-LARC', 'fridriksson-2-1114-LARC', 'NEURAL55-2']\n",
      "\n",
      "WAB: anomic\n",
      "Found datafiles in excel: 291\n",
      "Missing datafiles: 14\n",
      "Missing files:\n",
      "['fridriksson-2-1093-1', 'fridriksson-2-1026-LARC', 'fridriksson-2-1029-LARC', 'fridriksson-2-1049-LARC', 'fridriksson-2-1065-4', 'fridriksson-2-1065-5', 'fridriksson-2-1065-6', 'fridriksson-2-1065-LARC', 'fridriksson-2-1069-LARC', 'fridriksson-2-1084-LARC', 'fridriksson-2-1093-LARC', 'fridriksson-2-1104-LARC', 'fridriksson-2-1109-LARC', 'fridriksson-2-1113-LARC']\n",
      "\n",
      "WAB: not aphasic\n",
      "Found datafiles in excel: 91\n",
      "Missing datafiles: 2\n",
      "Missing files:\n",
      "['fridriksson-2-1022-1', 'TCU10b']\n"
     ]
    }
   ],
   "source": [
    "for x in aphasia_type:\n",
    "    list = files_df.loc[(files_df['WAB Type'] == x)]\n",
    "    print('WAB: '+x)\n",
    "    print('Found datafiles in excel: '+str(len(list)))\n",
    "    list = list.loc[(list['path'].isna())]\n",
    "    print('Missing datafiles: ' + str(len(list)))\n",
    "    print('Missing files:')\n",
    "    print(list['Participant ID'].to_list())\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T13:24:16.770784700Z",
     "start_time": "2024-11-01T13:24:16.756372400Z"
    }
   },
   "id": "7de8074c26b56ca5"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "files_df.to_csv('../ab_data/filepaths.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T13:24:16.783157Z",
     "start_time": "2024-11-01T13:24:16.770784700Z"
    }
   },
   "id": "1cdd0a0f144e3d91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
