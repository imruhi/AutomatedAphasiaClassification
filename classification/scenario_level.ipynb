{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9668d2b1341b259",
   "metadata": {
    "id": "e9668d2b1341b259",
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.795586600Z",
     "start_time": "2024-11-14T13:22:57.870452400Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from transformers import logging\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UndefinedMetricWarning)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.807592900Z",
     "start_time": "2024-11-14T13:22:58.799132100Z"
    }
   },
   "id": "498275f61bb9c1cf"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f92633d613951ef",
   "metadata": {
    "id": "9f92633d613951ef",
    "outputId": "4e6e950b-2823-4a86-d814-9da9703d8c31",
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.856746Z",
     "start_time": "2024-11-14T13:22:58.808731800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "test_env = False\n",
    "\n",
    "fp = \"../ab_data/experiment_data/\"\n",
    "model_fp = '../models/scenario_level/'\n",
    "\n",
    "dataset_fp = [fp+'conduction_anomic.csv', fp+'conduction_anomic_control.csv', \n",
    "              fp+'control_anomic.csv', fp+'wernicke_anomic.csv', \n",
    "              fp+'wernicke_anomic_control.csv', fp+'control_conduction.csv',\n",
    "              fp+'control_wernicke.csv', fp+'anomic_conduction_wernicke.csv',\n",
    "              fp+'control_non aphasic.csv']\n",
    "\n",
    "fnames = [model_fp+'conduction_anomic', model_fp+'conduction_anomic_control',\n",
    "          model_fp+'control_anomic', model_fp+'wernicke_anomic',\n",
    "          model_fp+'wernicke_anomic_control', model_fp+'control_conduction',\n",
    "          model_fp+'control_wernicke', model_fp+'anomic_conduction_wernicke',\n",
    "          model_fp+'control_non_aphasic']\n",
    "\n",
    "ids2labels = [{0: \"ANOMIC\", 1: \"CONDUCTION\"}, {0: \"CONTROL\", 1: \"ANOMIC\", 2: \"CONDUCTION\"},\n",
    "              {0: \"CONTROL\", 1: \"ANOMIC\"}, {0: \"ANOMIC\", 1: \"WERNICKE\"}, \n",
    "              {0: \"CONTROL\", 1: \"ANOMIC\", 2: \"WERNICKE\"}, {0: \"CONTROL\", 1: \"CONDUCTION\"},\n",
    "              {0: \"CONTROL\", 1:\"WERNICKE\"}, {0: \"CONDUCTION\", 1: \"ANOMIC\", 2: \"WERNICKE\"},\n",
    "              {0: \"CONTROL\", 1: \"NOT APHASIC\"}]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.874574Z",
     "start_time": "2024-11-14T13:22:58.831581400Z"
    }
   },
   "id": "5007f317ede01881"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dceb02e5146993dc",
   "metadata": {
    "id": "dceb02e5146993dc",
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.874574Z",
     "start_time": "2024-11-14T13:22:58.847699100Z"
    }
   },
   "outputs": [],
   "source": [
    "# non-binary classification metrics\n",
    "def compute_metrics3(eval_pred):\n",
    "    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n",
    "    metric={}\n",
    "    for met in metrics:\n",
    "       metric[met] = evaluate.load(met)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    metric_res={}\n",
    "\n",
    "    # micro, macro and weighted scores since it is a multi-class\n",
    "    # classification\n",
    "    for met in metrics:\n",
    "        if met != \"accuracy\":\n",
    "            metric_res[met+\"_micro\"] = round(metric[met].compute(predictions=predictions, references=labels, average=\"micro\")[met], 5)\n",
    "\n",
    "            metric_res[met+\"_macro\"] = round(metric[met].compute(predictions=predictions, references=labels, average=\"macro\")[met], 5)\n",
    "\n",
    "            metric_res[met+\"_weighted\"] = round(metric[met].compute(predictions=predictions, references=labels, average=\"weighted\")[met], 5)\n",
    "        else:\n",
    "            metric_res[met]=round(metric[met].compute(predictions=predictions, references=labels)[met], 5)\n",
    "    print(metric_res)\n",
    "    return metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# binary classification metrics\n",
    "def compute_metrics2(eval_pred):\n",
    "    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n",
    "    metric={}\n",
    "    for met in metrics:\n",
    "       metric[met] = evaluate.load(met)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    metric_res={}\n",
    "    for met in metrics:\n",
    "       metric_res[met]=round(metric[met].compute(predictions=predictions,\n",
    "       references=labels)[met], 5)\n",
    "    print(metric_res)\n",
    "    return metric_res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.874574Z",
     "start_time": "2024-11-14T13:22:58.858955200Z"
    }
   },
   "id": "e413b40bb36e9aa1"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def def_model(id2label_):\n",
    "    \"\"\"\n",
    "    Creates a distilbert uncased sequence classification model and tokenizer with new added tokens\n",
    "    :param id2label_: (dict) aphasic groups and their corresponding ids\n",
    "    :return: bert model and bert tokenizer\n",
    "    \"\"\"\n",
    "    label2id = {v: k for k, v in id2label_.items()}\n",
    "    tokenizer_ = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    if len(label2id) == 2:\n",
    "        model_ = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label_, label2id=label2id)\n",
    "    else:\n",
    "        model_ = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3, id2label=id2label_, label2id=label2id)\n",
    "        \n",
    "    added_tokens = tokenizer_.add_tokens([\"FP1\"], special_tokens=True)\n",
    "    added_tokens1 =  tokenizer_.add_tokens([\"UP1\"], special_tokens=True)\n",
    "    added_tokens2 = tokenizer_.add_tokens([\"FP2\"], special_tokens=True)\n",
    "    added_tokens3 =  tokenizer_.add_tokens([\"UP2\"], special_tokens=True)\n",
    "    added_tokens4 = tokenizer_.add_tokens([\"FP3\"], special_tokens=True)\n",
    "    added_tokens5 =  tokenizer_.add_tokens([\"UP3\"], special_tokens=True)\n",
    "    \n",
    "    print(\"We have added\", added_tokens + added_tokens1 + added_tokens2 + added_tokens3 + added_tokens4 +\n",
    "          added_tokens5, \"tokens\")\n",
    "    model_.resize_token_embeddings(len(tokenizer_))\n",
    "    \n",
    "    return model_, tokenizer_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.912420900Z",
     "start_time": "2024-11-14T13:22:58.874574Z"
    }
   },
   "id": "ebc8a66ac6d2e218"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def def_dataset(dataset_filename_, id2label_, tokenizer, testing=False):\n",
    "    \"\"\"\n",
    "    Creates a 70 train/ 30 test dataset with stratification and with fixed randomization (seed=42) \n",
    "    :param tokenizer: bert tokenizer\n",
    "    :param dataset_filename_: (str) filepath of the datasest\n",
    "    :param id2label_: (dict) aphasic groups and their corresponding ids\n",
    "    :param testing: (bool) whether in testing or not\n",
    "    :return: tokenized and split dataset as a Dataset instance \n",
    "    \"\"\"\n",
    "    label2id = {v: k for k, v in id2label_.items()}\n",
    "    data = pd.read_csv(dataset_filename_).dropna()\n",
    "    data[\"label\"] = [label2id[x] for x in data[\"label\"]]\n",
    "    print(data['label'].unique())\n",
    "    # for testing \n",
    "    if testing:\n",
    "        data = data[:100]\n",
    "    dataset = Dataset.from_pandas(data)\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"new_preprocessed_text\"], padding=True, truncation=True, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    tokenized_data = dataset.map(preprocess_function, batched=True).with_format(\"torch\")\n",
    "    tokenized_data_split_ = tokenized_data.train_test_split(test_size=0.3, seed=42)\n",
    "    return tokenized_data_split_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.919731900Z",
     "start_time": "2024-11-14T13:22:58.898160300Z"
    }
   },
   "id": "86e7afb8d77dc5d9"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def def_train_args(fname_):\n",
    "    \"\"\"\n",
    "    Creates the training args for the training procedure\n",
    "    :param fname_: (str) filepath to the model's save/log files\n",
    "    :return: the training arguments \n",
    "    \"\"\"\n",
    "    training_args_ = TrainingArguments(\n",
    "        output_dir=fname_+\"/train\",\n",
    "        logging_dir=fname_+\"/logs\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3 if \"wernicke\" in fname_ else 5, # 3 for wernicke including, otherwise 5\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=False,\n",
    "        use_cpu = False,\n",
    "        log_level = 'warning'\n",
    "    )\n",
    "    return training_args_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:22:58.919731900Z",
     "start_time": "2024-11-14T13:22:58.912363700Z"
    }
   },
   "id": "6514591df6e9724e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bdcaaf28048c7c1"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de9452bbc8581b59",
   "metadata": {
    "id": "de9452bbc8581b59",
    "ExecuteTime": {
     "end_time": "2024-11-14T13:23:17.084745800Z",
     "start_time": "2024-11-14T13:22:58.927694800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['ANOMIC', 'CONDUCTION']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2780 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ced2e929ee44ca3a35f82f8a5003d73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/1946 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89497a32e1404a36bb75ca2e13badc18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/834 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9759a46945f4915ab05b2985a1b85f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['CONTROL', 'ANOMIC', 'CONDUCTION']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4947 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3af38430651404f9c5eb32811e76702"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/3462 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c0d5ba4146a4879a38970b5ae959ed4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/1485 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e03388a81b554bfeb5ca6517bbceab1c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['CONTROL', 'ANOMIC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4015 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0dfb85da2e454b6e9dfdd86e95224676"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/2810 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a37917465d8c412b9b074e5efb813e34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/1205 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb233df6e1954589808946c174c9d220"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['ANOMIC', 'WERNICKE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/919 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9a10b9172f140ddb46b49774afbdac2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/643 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33531ba5acfd4dfeb4c24ee7318d1984"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/276 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3e6b7c5f1674a2599820524383d5972"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['CONTROL', 'ANOMIC', 'WERNICKE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[2 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1441 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a51f6426feb641ebbb64fe64f8c8f7dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/1008 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b624a9ad5ed74e43a922b99157d7b51d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/433 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "406c164358dc4cf8b68ab6fc4daaf21f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['CONTROL', 'CONDUCTION']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3099 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89a8d885fa7d4cef9888d38aea654690"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/2169 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97bb17428ba345f78bf3beaefa1b6a0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/930 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea75745f43f141639c3eabf370a85f84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['CONTROL', 'WERNICKE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/919 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b69473d7525b4d3c951078c5c98130e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/643 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04f0904dc4bb454a8c2d043d0cc15c60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/276 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a402649cc2e34b5c95925c909bf31918"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['CONDUCTION', 'ANOMIC', 'WERNICKE']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[1 0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1438 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2613ce5eebbd40509e2d711e7fc9cf8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/1006 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "335aa3457224488197c568f1eeb84509"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/432 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c60c5bf7b5e749ff967be30c23c51a19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: ['CONTROL', 'NOT APHASIC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 6 tokens\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2890 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cb5094118fe454d91cc8595601855b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/2023 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7fe1113ee474cdf9da1687e29ce1492"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/867 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd57cf24bf7b497abaed14f2ba2e8fd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train classifier\n",
    "\n",
    "for dataset_filename, fname, id2label in zip(dataset_fp, fnames, ids2labels):\n",
    "\n",
    "    print(f'Classifier: {list(id2label.values())}')\n",
    "    # define model, tokenizer, dataset and train args\n",
    "    model, tokenizer = def_model(id2label)\n",
    "    tokenized_data_split = def_dataset(dataset_filename, id2label, tokenizer, test_env)\n",
    "    tokenized_data_split.save_to_disk(fname + \"/dataset\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    training_args = def_train_args(fname)\n",
    "\n",
    "    # trainer = Trainer(\n",
    "    #         model=model,\n",
    "    #         args=training_args,\n",
    "    #         train_dataset=tokenized_data_split[\"train\"],\n",
    "    #         eval_dataset=tokenized_data_split[\"test\"],\n",
    "    #         tokenizer=tokenizer,\n",
    "    #         data_collator=data_collator,\n",
    "    #         compute_metrics=compute_metrics2 if len(id2label)==2 else compute_metrics3,\n",
    "    # \n",
    "    #     )\n",
    "    # \n",
    "    # # saving train output to txtfile (overwrite existing one)\n",
    "    # try:\n",
    "    #     os.remove(fname+\"/train_data.txt\")\n",
    "    # except OSError:\n",
    "    #     pass\n",
    "    # \n",
    "    # orig_stdout = sys.stdout\n",
    "    # sys.stdout = open(fname+\"/train_data.txt\",'wt')\n",
    "    # print('Train results per epoch\\n')\n",
    "    # # train model\n",
    "    # trainer.train()\n",
    "    # print('\\nTesting results\\n')\n",
    "    # # evaluate model \n",
    "    # trainer.evaluate()\n",
    "    # sys.stdout.close()\n",
    "    # sys.stdout=orig_stdout \n",
    "    # \n",
    "    # # save trained model and tokenizer with new tokens \n",
    "    # trainer.save_model(fname+\"/model\")\n",
    "    # tokenizer.save_pretrained(fname+\"/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe6a614e8092a",
   "metadata": {
    "collapsed": false,
    "id": "1bfe6a614e8092a"
   },
   "source": [
    "## Test model (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def test_model(fname_, dataset_filename_, id2label_, test_env_):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(fname_+\"/tokenizer\", return_tensor=\"pt\")\n",
    "    model_ = AutoModelForSequenceClassification.from_pretrained(fname_+\"/model\")\n",
    "    model_ = model_.to(device)\n",
    "    tokenized_data_split_ = def_dataset(dataset_filename_, id2label_, tokenizer, test_env_)\n",
    "    sentences = tokenized_data_split_[\"test\"][\"new_preprocessed_text\"]\n",
    "    true_labels = tokenized_data_split_[\"test\"][\"label\"]\n",
    "    pred_labels = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True, max_length=512).input_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model_(inputs).logits\n",
    "        predicted_class_id = logits.argmax().item()\n",
    "        pred_labels.append(predicted_class_id)\n",
    "    \n",
    "    true_labels = [id2label[x.to(torch.int64).item()] for x in true_labels]\n",
    "    pred_labels = [id2label[x] for x in pred_labels]\n",
    "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ConfusionMatrixDisplay.from_predictions(true_labels, pred_labels, normalize=\"true\", cmap=plt.cm.Blues, ax=ax)\n",
    "    plt.grid(False)\n",
    "    figname = '_'.join(list(id2label.values())).lower()\n",
    "    plt.savefig('scenario_level_output/'+figname+'.png')\n",
    "    # plt.savefig('not_aphasic_output/'+figname+'.png')\n",
    "    # saving test output to txtfile (overwrite existing one)\n",
    "    try:\n",
    "        os.remove('scenario_level_output/'+figname+'.txt')\n",
    "    except OSError:\n",
    "        pass\n",
    "    \n",
    "    orig_stdout = sys.stdout\n",
    "    sys.stdout = open('scenario_level_output/'+figname+'.txt','wt')\n",
    "    if len(id2label) == 2:\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2 * precision * recall)/ (precision+recall)\n",
    "        print(\"id2label=\" + str(id2label))\n",
    "        print(\"Accuracy: \" + str(round(accuracy_score(true_labels, pred_labels),5)))\n",
    "        print(\"Precision: \" + str(round(precision, 5)))\n",
    "        print(\"Recall: \" + str(round(recall,5)))\n",
    "        print(\"F1: \" + str(round(f1,5)))\n",
    "    else:\n",
    "        report = classification_report(true_labels, pred_labels, labels=np.unique(pred_labels), output_dict=True)\n",
    "        for k, v in report['macro avg'].items():\n",
    "            report['macro avg'][k] = round(v, 4)\n",
    "        for k, v in report['weighted avg'].items():\n",
    "            report['weighted avg'][k] = round(v, 4)\n",
    "\n",
    "        print(\"id2label=\" + str(id2label))\n",
    "        print(\"Accuracy: \" + str(round(accuracy_score(true_labels, pred_labels),4)))       \n",
    "        print(\"Macro avg: \" + str(report['macro avg']))\n",
    "        print(\"Weighted avg: \" + str(report['weighted avg']))\n",
    "    sys.stdout.close()\n",
    "    sys.stdout=orig_stdout "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:23:17.163502800Z",
     "start_time": "2024-11-14T13:23:17.096003200Z"
    }
   },
   "id": "c271601fef01b53e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "941df8a481a4b300"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# test the trained model on test set\n",
    "\n",
    "# for dataset_filename, fname, id2label in zip(dataset_fp, fnames, ids2labels):\n",
    "#     test_model(fname, dataset_filename, id2label, test_env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:23:17.165095800Z",
     "start_time": "2024-11-14T13:23:17.116421900Z"
    }
   },
   "id": "242952f825740145"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test models (on not aphasic dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c27d393dd1083779"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# test_env = False\n",
    "# \n",
    "# fp = \"../ab_data/processed_data/\"\n",
    "# model_fp = '../models/scenario_level/'\n",
    "# \n",
    "# dataset_fp = fp + 'processeddata_not aphasic_para.csv'\n",
    "# \n",
    "# fnames = [model_fp+'conduction_anomic_control',\n",
    "#           model_fp+'control_anomic', \n",
    "#           model_fp+'wernicke_anomic_control', \n",
    "#           model_fp+'control_conduction',\n",
    "#           model_fp+'control_wernicke']\n",
    "# \n",
    "# # Here control = NOT APHASIC\n",
    "# ids2labels = [{0: \"CONTROL\", 1: \"ANOMIC\", 2: \"CONDUCTION\"},\n",
    "#               {0: \"CONTROL\", 1: \"ANOMIC\"}, \n",
    "#               {0: \"CONTROL\", 1: \"ANOMIC\", 2: \"WERNICKE\"}, \n",
    "#               {0: \"CONTROL\", 1: \"CONDUCTION\"},\n",
    "#               {0: \"CONTROL\", 1:\"WERNICKE\"}]\n",
    "# \n",
    "# # df = pd.read_csv(dataset_fp)\n",
    "# # df['label'] = ['CONTROL']*len(df)\n",
    "# # df.to_csv(dataset_fp,index=None)\n",
    "# \n",
    "# for id2label, model, in zip(ids2labels, fnames):\n",
    "#     test_model(model, dataset_fp, id2label, test_env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:23:17.165095800Z",
     "start_time": "2024-11-14T13:23:17.125845200Z"
    }
   },
   "id": "1ac044626a24aaa2"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-14T13:23:17.165095800Z",
     "start_time": "2024-11-14T13:23:17.140690500Z"
    }
   },
   "id": "f796ea5fa559fdab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
