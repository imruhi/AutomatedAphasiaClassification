{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72436407-1cc2-49fb-a5da-4861772c2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out to run on drive + colab \n",
    "\n",
    "# ! pip install transformers_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc44bb-522b-42f5-b989-ac247e51e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# \n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51a91a14a5feeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:43.254715800Z",
     "start_time": "2024-03-22T12:34:37.300705200Z"
    },
    "id": "6a51a91a14a5feeb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers_interpret import MultiLabelClassificationExplainer\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1db4f-1501-4650-bba1-a0e7e51486f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.331934600Z",
     "start_time": "2024-03-22T12:34:43.256715500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "999c8ae1-f24d-4eee-a7e9-d38a1ac2425e"
   },
   "outputs": [],
   "source": [
    "# comment out the filepath to run on drive + colab \n",
    "filepath = \"../models/scenario_level/anomic_wernicke_control\"\n",
    "# filepath = \"/content/drive/Shareddrives/AphasiaProject/models/scenario_level/anomic_wernicke_control\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(filepath+\"/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(filepath+\"/tokenizer\", padding=True, \n",
    "                                          truncation=True, return_tensors=\"pt\", \n",
    "                                          add_special_tokens=True, max_length=512)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    model.to(device)\n",
    "pipe = pipeline(\"text-classification\", model=filepath+\"/model\", tokenizer=filepath+\"/tokenizer\", device=device, truncation=True, padding=True)\n",
    "cls_explainer = MultiLabelClassificationExplainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3dbba-9fcc-48c7-85b6-a4c7e941e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cb5bcd0de03ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.356544300Z",
     "start_time": "2024-03-22T12:34:44.335077400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b24cb5bcd0de03ac",
    "outputId": "6f21449f-f3dd-4f55-db1b-769f462c4939"
   },
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cdc28-0dfb-4baf-ba38-40bf87f872b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(data):\n",
    "    for text, label in zip(list(data[\"new_preprocessed_text\"]), list(data[\"label\"])):\n",
    "        if device == torch.device(\"cuda\"):\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True, max_length=512).input_ids.to(device) \n",
    "            # tranformers interpret gives error for input of 512 tokens\n",
    "            if len(inputs[0]) != 512:\n",
    "                with torch.no_grad():\n",
    "                    logits = model(inputs).logits\n",
    "                    \n",
    "                predicted_class_id = logits.argmax().item()\n",
    "                print(\"True: \", label, \"Pred: \", model.config.id2label[predicted_class_id])\n",
    "                print(\"Text: \", text)\n",
    "                cls_explainer(text)\n",
    "                cls_explainer.visualize()\n",
    "                print(\"----------------------------------------------------------------------\")\n",
    "        else:\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True, max_length=512) \n",
    "            # tranformers interpret gives error for input of 512 tokens\n",
    "            if len(inputs[0]) != 512:    \n",
    "                with torch.no_grad():\n",
    "                    logits = model(**inputs).logits\n",
    "                    \n",
    "                predicted_class_id = logits.argmax().item()\n",
    "                print(\"True: \", label, \"Pred: \", model.config.id2label[predicted_class_id])\n",
    "                print(\"Text: \", text)\n",
    "                cls_explainer(text)\n",
    "                cls_explainer.visualize()\n",
    "                print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c04c41223854e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.437905200Z",
     "start_time": "2024-03-22T12:34:44.349775500Z"
    },
    "id": "aa6c04c41223854e"
   },
   "outputs": [],
   "source": [
    "scenarios = [\"Speech\", \"Important_Event\", \"Cinderella\", \"Stroke\", \"Cat\"]\n",
    "# make sure not to interpret on trained scenarios \n",
    "texts = load_from_disk(filepath + \"/dataset\")[\"test\"].remove_columns([\"Unnamed: 0\", \"input_ids\", \"attention_mask\"]).to_pandas()\n",
    "texts[\"label\"] = [model.config.id2label[x] for x in texts[\"label\"]]\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12b76f3bb4edc2",
   "metadata": {
    "collapsed": false,
    "id": "ca12b76f3bb4edc2",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Speech scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258e2e4-f18d-4ecc-8f84-3dc5e109aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[0])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d12cf8-a66a-44c4-af5e-b1362ed098b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dFr9AJeIU5q",
   "metadata": {
    "id": "8dFr9AJeIU5q"
   },
   "source": [
    "# Important event scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OBqNDFNBIf5_",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:35:15.974104900Z",
     "start_time": "2024-03-22T12:35:15.956563200Z"
    },
    "id": "OBqNDFNBIf5_"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[1])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713a3ca-eef5-4b59-9dc5-50e6cb6af0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TpeyPB9sIwi4",
   "metadata": {
    "id": "TpeyPB9sIwi4"
   },
   "source": [
    "# Cinderella scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1HJ-lx-zIwL0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.963563600Z"
    },
    "id": "1HJ-lx-zIwL0"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[2])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aeaac3-ec1c-4fb5-8b9b-0a9a8b02c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnsihBHYI_LP",
   "metadata": {
    "id": "mnsihBHYI_LP"
   },
   "source": [
    "# Stroke scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROQxqFWOI9I-",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.971103800Z"
    },
    "id": "ROQxqFWOI9I-"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    df = texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[3])]\n",
    "    # no controls in stroke scenario\n",
    "    if len(df) >= n:\n",
    "        data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[3])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794536e-ecdc-4b01-b941-b6cee1e4a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oWhPSLlFJGTh",
   "metadata": {
    "id": "oWhPSLlFJGTh"
   },
   "source": [
    "# Cat scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sZhsEUPwJJpq",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.978303600Z"
    },
    "id": "sZhsEUPwJJpq"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[4])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942450e3-0651-407b-a1d3-b1e4e6844615",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
