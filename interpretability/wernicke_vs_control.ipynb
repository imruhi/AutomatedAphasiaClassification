{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749c011-07b9-4ab1-a25f-1e0128aff367",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95082,
     "status": "ok",
     "timestamp": 1712658493466,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "d749c011-07b9-4ab1-a25f-1e0128aff367",
    "outputId": "e94c2bb5-af1d-4f8c-a0ff-7575d690ec0b"
   },
   "outputs": [],
   "source": [
    "# comment out to run on drive + colab\n",
    "\n",
    "! pip install transformers_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Jf-0rxWVZpk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21111,
     "status": "ok",
     "timestamp": 1712657722538,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "-Jf-0rxWVZpk",
    "outputId": "013caeaf-fb93-4c6b-8e8a-623dceca0517"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47325d21-3e12-41c1-bf3b-c6dd87f452a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12946,
     "status": "ok",
     "timestamp": 1712658354913,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "47325d21-3e12-41c1-bf3b-c6dd87f452a4",
    "outputId": "e6f9231e-ebd5-453c-b60d-b3af24197d9e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "#\n",
    "# drive.mount('/content/drive/')\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51a91a14a5feeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:43.254715800Z",
     "start_time": "2024-03-22T12:34:37.300705200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 12151,
     "status": "error",
     "timestamp": 1712658381005,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "6a51a91a14a5feeb",
    "outputId": "09923f6e-e227-4060-88f4-9f733f89b2fa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers_interpret import MultiLabelClassificationExplainer\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbdfa63-33d3-4ca8-bb78-4ccf03d5e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.331934600Z",
     "start_time": "2024-03-22T12:34:43.256715500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "999c8ae1-f24d-4eee-a7e9-d38a1ac2425e"
   },
   "outputs": [],
   "source": [
    "# comment out the filepath to run on drive + colab\n",
    "filepath = \"../models/scenario_level/wernicke_control\"\n",
    "# filepath = \"/content/drive/Shareddrives/AphasiaProject/models/scenario_level/wernicke_control\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(filepath+\"/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(filepath+\"/tokenizer\", padding=True,\n",
    "                                          truncation=True, return_tensors=\"pt\",\n",
    "                                          add_special_tokens=True, max_length=512)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    model.to(device)\n",
    "pipe = pipeline(\"text-classification\", model=filepath+\"/model\", tokenizer=filepath+\"/tokenizer\", device=device, truncation=True, padding=True)\n",
    "cls_explainer = MultiLabelClassificationExplainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3dbba-9fcc-48c7-85b6-a4c7e941e430",
   "metadata": {
    "id": "9ae3dbba-9fcc-48c7-85b6-a4c7e941e430",
    "outputId": "083eb7c0-fff5-4e3f-c002-78f907a9643c"
   },
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cb5bcd0de03ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.356544300Z",
     "start_time": "2024-03-22T12:34:44.335077400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b24cb5bcd0de03ac",
    "outputId": "6f21449f-f3dd-4f55-db1b-769f462c4939"
   },
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cdc28-0dfb-4baf-ba38-40bf87f872b3",
   "metadata": {
    "id": "b41cdc28-0dfb-4baf-ba38-40bf87f872b3"
   },
   "outputs": [],
   "source": [
    "def interpret(data):\n",
    "    for text, label in zip(list(data[\"new_preprocessed_text\"]), list(data[\"label\"])):\n",
    "        if device == torch.device(\"cuda\"):\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True, max_length=512).input_ids.to(device)\n",
    "            # tranformers interpret gives error for input of 512 tokens\n",
    "            if len(inputs[0]) != 512:\n",
    "                with torch.no_grad():\n",
    "                    logits = model(inputs).logits\n",
    "\n",
    "                predicted_class_id = logits.argmax().item()\n",
    "                print(\"True: \", label, \"Pred: \", model.config.id2label[predicted_class_id])\n",
    "                print(\"Text: \", text)\n",
    "                cls_explainer(text)\n",
    "                cls_explainer.visualize()\n",
    "                print(\"----------------------------------------------------------------------\")\n",
    "        else:\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True, max_length=512)\n",
    "            # tranformers interpret gives error for input of 512 tokens\n",
    "            if len(inputs[0]) != 512:\n",
    "                with torch.no_grad():\n",
    "                    logits = model(**inputs).logits\n",
    "\n",
    "                predicted_class_id = logits.argmax().item()\n",
    "                print(\"True: \", label, \"Pred: \", model.config.id2label[predicted_class_id])\n",
    "                print(\"Text: \", text)\n",
    "                cls_explainer(text)\n",
    "                cls_explainer.visualize()\n",
    "                print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c04c41223854e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.437905200Z",
     "start_time": "2024-03-22T12:34:44.349775500Z"
    },
    "id": "aa6c04c41223854e"
   },
   "outputs": [],
   "source": [
    "scenarios = [\"Speech\", \"Important_Event\", \"Cinderella\", \"Stroke\", \"Cat\"]\n",
    "# make sure not to interpret on trained scenarios\n",
    "texts = load_from_disk(filepath + \"/dataset\")[\"test\"].remove_columns([\"Unnamed: 0\", \"input_ids\", \"attention_mask\"]).to_pandas()\n",
    "texts[\"label\"] = [model.config.id2label[x] for x in texts[\"label\"]]\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12b76f3bb4edc2",
   "metadata": {
    "collapsed": false,
    "id": "ca12b76f3bb4edc2",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Speech scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258e2e4-f18d-4ecc-8f84-3dc5e109aad9",
   "metadata": {
    "id": "9258e2e4-f18d-4ecc-8f84-3dc5e109aad9"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[0])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d12cf8-a66a-44c4-af5e-b1362ed098b7",
   "metadata": {
    "id": "d0d12cf8-a66a-44c4-af5e-b1362ed098b7",
    "outputId": "65ced465-cf9b-4a8d-dedb-86bdc2087457"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dFr9AJeIU5q",
   "metadata": {
    "id": "8dFr9AJeIU5q"
   },
   "source": [
    "# Important event scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OBqNDFNBIf5_",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:35:15.974104900Z",
     "start_time": "2024-03-22T12:35:15.956563200Z"
    },
    "id": "OBqNDFNBIf5_"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[1])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713a3ca-eef5-4b59-9dc5-50e6cb6af0ae",
   "metadata": {
    "id": "8713a3ca-eef5-4b59-9dc5-50e6cb6af0ae",
    "outputId": "26198a6f-c3d7-4602-a8a1-269f3987bb74"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TpeyPB9sIwi4",
   "metadata": {
    "id": "TpeyPB9sIwi4"
   },
   "source": [
    "# Cinderella scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1HJ-lx-zIwL0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.963563600Z"
    },
    "id": "1HJ-lx-zIwL0"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[2])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aeaac3-ec1c-4fb5-8b9b-0a9a8b02c7dc",
   "metadata": {
    "id": "86aeaac3-ec1c-4fb5-8b9b-0a9a8b02c7dc",
    "outputId": "0ea08f0d-bf22-49a6-a002-09df676f0e75"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnsihBHYI_LP",
   "metadata": {
    "id": "mnsihBHYI_LP"
   },
   "source": [
    "# Stroke scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROQxqFWOI9I-",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.971103800Z"
    },
    "id": "ROQxqFWOI9I-"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    df = texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[3])]\n",
    "    # no controls in stroke scenario\n",
    "    if len(df) >= n:\n",
    "        data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[3])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794536e-ecdc-4b01-b941-b6cee1e4a2d1",
   "metadata": {
    "id": "9794536e-ecdc-4b01-b941-b6cee1e4a2d1",
    "outputId": "7f864caa-794c-4aad-f3d2-a81df5cadebf"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oWhPSLlFJGTh",
   "metadata": {
    "id": "oWhPSLlFJGTh"
   },
   "source": [
    "# Cat scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sZhsEUPwJJpq",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.978303600Z"
    },
    "id": "sZhsEUPwJJpq"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[4])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942450e3-0651-407b-a1d3-b1e4e6844615",
   "metadata": {
    "id": "942450e3-0651-407b-a1d3-b1e4e6844615",
    "outputId": "3519ecde-7798-4774-8709-9a736a1eda7d"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
