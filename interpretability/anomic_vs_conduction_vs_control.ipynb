{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134c77e-15ae-4ff6-88d0-49b338b63235",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97685,
     "status": "ok",
     "timestamp": 1712656323791,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "0134c77e-15ae-4ff6-88d0-49b338b63235",
    "outputId": "d9947fc5-b654-4bbe-e387-55d74afddcdf"
   },
   "outputs": [],
   "source": [
    "# comment out to run on drive + colab\n",
    "# !pip install transformers_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501484d7-6aa0-4240-a730-508a2a537b6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94144,
     "status": "ok",
     "timestamp": 1712656496874,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "501484d7-6aa0-4240-a730-508a2a537b6f",
    "outputId": "7131528b-da75-4332-9976-d65651bcbf5d"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/drive/')\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lU28NiO3TB6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13013,
     "status": "ok",
     "timestamp": 1712656770965,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "lU28NiO3TB6d",
    "outputId": "1c3e1a6c-a981-4952-bfec-4a4ab4c58e4d"
   },
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XXFeUhxVSqHI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2073,
     "status": "ok",
     "timestamp": 1712656795461,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "XXFeUhxVSqHI",
    "outputId": "9470c92d-c4de-478c-d93c-250b71fe1468"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51a91a14a5feeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:43.254715800Z",
     "start_time": "2024-03-22T12:34:37.300705200Z"
    },
    "executionInfo": {
     "elapsed": 1119,
     "status": "ok",
     "timestamp": 1712656786467,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "6a51a91a14a5feeb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers_interpret import MultiLabelClassificationExplainer\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122266a-8610-4522-9110-92df9b91105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.331934600Z",
     "start_time": "2024-03-22T12:34:43.256715500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17998,
     "status": "ok",
     "timestamp": 1712656838711,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "initial_id",
    "outputId": "6f4ddf9d-79bd-4d59-e204-4557a54d5ad5"
   },
   "outputs": [],
   "source": [
    "# comment out the filepath to run on drive + colab\n",
    "filepath = \"../models/scenario_level/conduction_anomic_control\"\n",
    "# filepath = \"/content/drive/Shareddrives/AphasiaProject/models/scenario_level/conduction_anomic_control\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(filepath+\"/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(filepath+\"/tokenizer\", padding=True,\n",
    "                                          truncation=True, return_tensors=\"pt\",\n",
    "                                          max_length=512)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == torch.device(\"cuda\"):\n",
    "    model.to(device)\n",
    "pipe = pipeline(\"text-classification\", model=filepath+\"/model\", tokenizer=filepath+\"/tokenizer\", device=device, truncation=True, padding=True)\n",
    "cls_explainer = MultiLabelClassificationExplainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3dbba-9fcc-48c7-85b6-a4c7e941e430",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1712656850799,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "9ae3dbba-9fcc-48c7-85b6-a4c7e941e430",
    "outputId": "beb241b3-2953-4939-b167-cf358d710c37"
   },
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cb5bcd0de03ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.356544300Z",
     "start_time": "2024-03-22T12:34:44.335077400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1712656859524,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "b24cb5bcd0de03ac",
    "outputId": "ee891835-268e-45d8-b41e-51c091182bee"
   },
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cdc28-0dfb-4baf-ba38-40bf87f872b3",
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1712656878389,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "b41cdc28-0dfb-4baf-ba38-40bf87f872b3"
   },
   "outputs": [],
   "source": [
    "def interpret(data):\n",
    "    for text, label in zip(list(data[\"new_preprocessed_text\"]), list(data[\"label\"])):\n",
    "        if device == torch.device(\"cuda\"):\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True, max_length=512).input_ids.to(device)\n",
    "            # tranformers interpret gives error for input of 512 tokens\n",
    "            if len(inputs[0]) != 512:\n",
    "                with torch.no_grad():\n",
    "                    logits = model(inputs).logits\n",
    "\n",
    "                predicted_class_id = logits.argmax().item()\n",
    "                print(\"True: \", label, \"Pred: \", model.config.id2label[predicted_class_id])\n",
    "                print(\"Text: \", text)\n",
    "                cls_explainer(text)\n",
    "                cls_explainer.visualize()\n",
    "                print(\"----------------------------------------------------------------------\")\n",
    "        else:\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True, max_length=512)\n",
    "            # tranformers interpret gives error for input of 512 tokens\n",
    "            if len(inputs[0]) != 512:\n",
    "                with torch.no_grad():\n",
    "                    logits = model(**inputs).logits\n",
    "\n",
    "                predicted_class_id = logits.argmax().item()\n",
    "                print(\"True: \", label, \"Pred: \", model.config.id2label[predicted_class_id])\n",
    "                print(\"Text: \", text)\n",
    "                cls_explainer(text)\n",
    "                cls_explainer.visualize()\n",
    "                print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c04c41223854e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:34:44.437905200Z",
     "start_time": "2024-03-22T12:34:44.349775500Z"
    },
    "executionInfo": {
     "elapsed": 4913,
     "status": "ok",
     "timestamp": 1712656896398,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "aa6c04c41223854e"
   },
   "outputs": [],
   "source": [
    "scenarios = [\"Speech\", \"Important_Event\", \"Cinderella\", \"Stroke\", \"Cat\"]\n",
    "# make sure not to interpret on trained scenarios\n",
    "texts = load_from_disk(filepath + \"/dataset\")[\"test\"].remove_columns([\"Unnamed: 0\", \"input_ids\", \"attention_mask\"]).to_pandas()\n",
    "texts[\"label\"] = [model.config.id2label[x] for x in texts[\"label\"]]\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12b76f3bb4edc2",
   "metadata": {
    "collapsed": false,
    "id": "ca12b76f3bb4edc2",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Speech scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258e2e4-f18d-4ecc-8f84-3dc5e109aad9",
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1712656903889,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "9258e2e4-f18d-4ecc-8f84-3dc5e109aad9"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[0])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d12cf8-a66a-44c4-af5e-b1362ed098b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 474451,
     "status": "ok",
     "timestamp": 1712657381654,
     "user": {
      "displayName": "F. Tsiwah",
      "userId": "17094998878608097993"
     },
     "user_tz": -120
    },
    "id": "d0d12cf8-a66a-44c4-af5e-b1362ed098b7",
    "outputId": "62c7f1df-0a29-4968-fdae-681244fc32ff"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dFr9AJeIU5q",
   "metadata": {
    "id": "8dFr9AJeIU5q"
   },
   "source": [
    "# Important event scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OBqNDFNBIf5_",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T12:35:15.974104900Z",
     "start_time": "2024-03-22T12:35:15.956563200Z"
    },
    "id": "OBqNDFNBIf5_"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[1])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713a3ca-eef5-4b59-9dc5-50e6cb6af0ae",
   "metadata": {
    "id": "8713a3ca-eef5-4b59-9dc5-50e6cb6af0ae",
    "outputId": "4358fe0f-065b-48f8-a289-ea03f8161084"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TpeyPB9sIwi4",
   "metadata": {
    "id": "TpeyPB9sIwi4"
   },
   "source": [
    "# Cinderella scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1HJ-lx-zIwL0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.963563600Z"
    },
    "id": "1HJ-lx-zIwL0"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[2])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aeaac3-ec1c-4fb5-8b9b-0a9a8b02c7dc",
   "metadata": {
    "id": "86aeaac3-ec1c-4fb5-8b9b-0a9a8b02c7dc",
    "outputId": "5ac2c8d0-3f48-4d59-8621-567948531b3f"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mnsihBHYI_LP",
   "metadata": {
    "id": "mnsihBHYI_LP"
   },
   "source": [
    "# Stroke scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROQxqFWOI9I-",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.971103800Z"
    },
    "id": "ROQxqFWOI9I-"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    df = texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[3])]\n",
    "    # no controls in stroke scenario\n",
    "    if len(df) >= n:\n",
    "        data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[3])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794536e-ecdc-4b01-b941-b6cee1e4a2d1",
   "metadata": {
    "id": "9794536e-ecdc-4b01-b941-b6cee1e4a2d1",
    "outputId": "6ba5297a-09fa-497c-e174-1faa6ec6d5b7"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oWhPSLlFJGTh",
   "metadata": {
    "id": "oWhPSLlFJGTh"
   },
   "source": [
    "# Cat scenario interpretation\n",
    "Three examples for conduction and three for control (# of examples defined by n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sZhsEUPwJJpq",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T12:35:15.978303600Z"
    },
    "id": "sZhsEUPwJJpq"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['label','new_preprocessed_text','scenario'])\n",
    "\n",
    "for x in model.config.label2id.keys():\n",
    "    data = pd.concat([data, texts[(texts[\"label\"] == x) & (texts[\"scenario\"] == scenarios[4])].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942450e3-0651-407b-a1d3-b1e4e6844615",
   "metadata": {
    "id": "942450e3-0651-407b-a1d3-b1e4e6844615",
    "outputId": "5b6a9f6d-d33f-4db3-ad1e-35e6ac188ec6"
   },
   "outputs": [],
   "source": [
    "interpret(data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
